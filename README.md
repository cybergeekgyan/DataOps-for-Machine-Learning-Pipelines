# DataOps-for-Machine-Learning-Pipelines


## Project Overview

- This project demonstrates the integration of DataOps principles into machine learning (ML) pipelines. It encompasses the full lifecycle of an ML pipeline, including 
    - `data ingestion`, `data-preprocessing`, `model training`, `validation-checks`, and `deployment`. 
- The pipeline is orchestrated using `Apache Airflow` and leverages `MLflow` for experiment tracking and model management.

## Technologies Used

- [Apache Airflow](): For orchestrating and scheduling the ML workflows.
- [MLflow](): For managing ML experiments and model versioning.
- [PostgreSQL](): For data storage.
- [Python](): For scripting data ingestion, preprocessing, and model training.
- [Docker](): For containerizing and running services.

## Getting Started

### Pre-requisites

- Python
- Docker

### Setup Instructions


